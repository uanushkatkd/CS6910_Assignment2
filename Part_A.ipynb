{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nprint(torch.device('cuda:0'))\nprint(torch.__version__)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2023-04-07T10:24:31.598164Z","iopub.execute_input":"2023-04-07T10:24:31.599350Z","iopub.status.idle":"2023-04-07T10:24:32.658255Z","shell.execute_reply.started":"2023-04-07T10:24:31.599299Z","shell.execute_reply":"2023-04-07T10:24:32.657063Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"cuda:0\n1.13.0\ncuda\n","output_type":"stream"}]},{"cell_type":"code","source":"!wget 'https://storage.googleapis.com/wandb_datasets/nature_12K.zip'\n!unzip -q nature_12K.zip","metadata":{"execution":{"iopub.status.busy":"2023-04-07T09:25:23.279048Z","iopub.execute_input":"2023-04-07T09:25:23.279788Z","iopub.status.idle":"2023-04-07T09:26:09.920889Z","shell.execute_reply.started":"2023-04-07T09:25:23.279751Z","shell.execute_reply":"2023-04-07T09:26:09.919269Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"--2023-04-07 09:25:24--  https://storage.googleapis.com/wandb_datasets/nature_12K.zip\nResolving storage.googleapis.com (storage.googleapis.com)... 74.125.69.128, 64.233.182.128, 173.194.193.128, ...\nConnecting to storage.googleapis.com (storage.googleapis.com)|74.125.69.128|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 3816687935 (3.6G) [application/zip]\nSaving to: ‘nature_12K.zip’\n\nnature_12K.zip      100%[===================>]   3.55G   208MB/s    in 17s     \n\n2023-04-07 09:25:40 (221 MB/s) - ‘nature_12K.zip’ saved [3816687935/3816687935]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# imports\nimport math\nimport torch\nimport torch.nn.functional as F  # Parameterless functions, like (some) activation functions\nimport torchvision.datasets as datasets  # Standard datasets\nimport torchvision.transforms as transforms  # Transformations we can perform on our dataset for augmentation\nfrom torch import optim  # For optimizers like SGD, Adam, etc.\nfrom torch import nn  # All neural network modules\nfrom torch.utils.data import (\n    DataLoader, random_split\n)  # Gives easier dataset managment by creating mini batches etc.\nfrom tqdm import tqdm  # For nice progress bar!\n\nfrom torchvision.datasets import ImageFolder\nimport os\nimport random\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pathlib\n \n\n# Dataset Augmentation \ndef load_data(bs,augment_data=False):\n    # define the transforms to be applied to the training data\n    if augment_data:\n        train_transforms = transforms.Compose([\n          transforms.Resize((300,300)),\n          transforms.RandomHorizontalFlip(),\n          transforms.RandomRotation(10),\n          transforms.ToTensor(),\n          transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n      ])\n    else:\n        train_transforms = transforms.Compose([\n          transforms.Resize((300,300)),\n          transforms.ToTensor(),\n          transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n      ])\n    \n    test_transforms = transforms.Compose([\n      transforms.Resize((300,300)),\n      transforms.ToTensor(),\n      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n  ])\n\n\n    home_path = \"/kaggle/working/inaturalist_12K\"\n\n    train_path = os.path.join(home_path,'train')\n    test_path = os.path.join(home_path,'val')\n    # define the dataset and apply the transforms\n    train_dataset = ImageFolder(train_path, transform=train_transforms)\n    test_dataset = ImageFolder(test_path, transform=test_transforms)\n\n    # split training dataset into train and validation sets\n    train_size = int(0.8 * len(train_dataset))\n    print(train_size)\n    val_size = len(train_dataset) - train_size\n    print(val_size)\n\n    train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n\n    # create a data loader for the training data\n    train_loader = torch.utils.data.DataLoader(train_dataset,bs, shuffle=True)\n    val_loader = torch.utils.data.DataLoader(val_dataset, bs, shuffle=False)\n    test_loader = torch.utils.data.DataLoader(test_dataset, bs, shuffle=False)\n\n    #categories\n    root=pathlib.Path(train_path)\n\n    classes=sorted([j.name.split('/')[-1] for j in root.iterdir()])\n\n    return train_loader,val_loader,test_loader,classes\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-04-07T10:24:55.382401Z","iopub.execute_input":"2023-04-07T10:24:55.383861Z","iopub.status.idle":"2023-04-07T10:24:55.630447Z","shell.execute_reply.started":"2023-04-07T10:24:55.383809Z","shell.execute_reply":"2023-04-07T10:24:55.629361Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"#Simple CNN\ndef flatten(k=[11,9,7,5,3],w=300, s=1, p=1):\n    r=w\n    for i in  range(len(k)):\n        print(\"r\",r)\n        r= (r+2*p-k[i])+1\n        r= int(r/2)+1\n    return r \n\n\nclass CNN(nn.Module):\n    def __init__(self, in_channels=3, num_class=10,num_filters=4,kernel_sizes=[11,9,7,5,3],fc_neurons=64,batch_norm=True,dropout=0.3,filter_multiplier=2,activation='LeakyRelu'):\n\n        super(CNN, self).__init__()\n        self.in_channels=in_channels\n        self.num_class=num_class\n        self.num_filters=num_filters\n        self.kernel_sizes=kernel_sizes\n        self.fc_neurons=fc_neurons\n        self.activation=activation\n        self.batch_norm=batch_norm\n        self.dropout=dropout\n        self.filter_multiplier=filter_multiplier\n        \n        #print(\"in1\")\n        self.conv1 = nn.Conv2d(3, num_filters, kernel_size=kernel_sizes[0],stride=1, padding=1).to(device)\n        #print(\"in2\")\n        self.bn1=nn.BatchNorm2d(num_features=num_filters)\n        self.relu1 = nn.LeakyReLU()\n\n        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2, padding=1)\n\n        self.conv2 = nn.Conv2d(num_filters,filter_multiplier*num_filters,  kernel_size=kernel_sizes[1],stride=1, padding=1).to(device)\n        self.bn2=nn.BatchNorm2d(num_features=filter_multiplier*num_filters)\n        self.relu2 = nn.LeakyReLU()\n\n        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2, padding=1)\n\n        self.conv3 = nn.Conv2d(filter_multiplier*num_filters, int(math.pow(filter_multiplier, 2))*num_filters, kernel_size=kernel_sizes[2],stride=1, padding=1).to(device)\n        self.bn3=nn.BatchNorm2d(num_features=int(math.pow(filter_multiplier, 2))*num_filters)\n        self.relu3 = nn.LeakyReLU()\n\n\n        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2, padding=1)\n\n        self.conv4 = nn.Conv2d(int(math.pow(filter_multiplier, 2))*num_filters, int(math.pow(filter_multiplier, 3))*num_filters, kernel_size=kernel_sizes[3],stride=1, padding=1).to(device)\n        self.bn4=nn.BatchNorm2d(num_features=int(math.pow(filter_multiplier, 3))*num_filters)\n        self.relu4 = nn.LeakyReLU()\n\n        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2, padding=1)\n\n        self.conv5 = nn.Conv2d(int(math.pow(filter_multiplier, 3))*num_filters, int(math.pow(filter_multiplier, 4))*num_filters, kernel_size=kernel_sizes[4],stride=1, padding=1).to(device)\n        self.bn5=nn.BatchNorm2d(num_features=int(math.pow(filter_multiplier, 4))*num_filters)\n        self.relu5 = nn.LeakyReLU()\n\n\n        self.pool5 = nn.MaxPool2d(kernel_size=2, stride=2, padding=1)\n        print(\"ok pool5\")\n        self.r=flatten(kernel_sizes)\n        print(\"ok flatten\")\n        print(self.r)\n        self.fc1 = nn.Linear(in_features=int(math.pow(filter_multiplier, 4))*num_filters*self.r*self.r, out_features=fc_neurons)\n        self.relu6 = nn.LeakyReLU()\n\n        self.drop = nn.Dropout(dropout)\n        \n        self.fc2 = nn.Linear(in_features=fc_neurons, out_features=num_class)\n    \n    def forward(self, x):\n        x = self.conv1(x)\n        if self.batch_norm:\n            x = self.bn1(x)\n        x = self.relu1(x)\n        \n        x = self.pool1(x)\n        \n        x = self.conv2(x)\n        if self.batch_norm:\n            x = self.bn2(x)\n        x = self.relu2(x)\n\n        x = self.pool2(x)\n\n        x = self.conv3(x)\n        if self.batch_norm:\n            x = self.bn3(x)\n        x = self.relu3(x)\n        \n        x = self.pool3(x)\n        \n        x = self.conv4(x)\n        if self.batch_norm:\n            x = self.bn4(x)\n        x = self.relu4(x)\n       \n        x = self.pool4(x)\n     \n        x = self.conv5(x)\n        if self.batch_norm:\n            x = self.bn5(x)\n        x = self.relu5(x)\n\n        x = self.pool5(x)\n        x = x.view(x.size(0),-1)\n\n        x = self.fc1(x)\n        x = self.relu6(x)\n        x = self.drop(x)\n        \n        x = self.fc2(x)\n        \n        return x\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-04-07T10:24:59.583519Z","iopub.execute_input":"2023-04-07T10:24:59.583910Z","iopub.status.idle":"2023-04-07T10:24:59.608651Z","shell.execute_reply.started":"2023-04-07T10:24:59.583864Z","shell.execute_reply":"2023-04-07T10:24:59.607296Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Set device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Hyperparameters\nin_channels = 3\nnum_class = 10\nlearning_rate = 0.0001\nbatch_size = 128\nepochs = 10\n\n# Load data\ntrain_loader,val_loader,test_loader,classes=load_data(batch_size)\nprint(classes)\ntrainfeature, trainlabel = next(iter(train_loader))\nprint(f\"Feature Batch Shape: {trainfeature.size()}\")\nprint(f\"Label Batch Shape: {trainlabel.size()}\")\n\n\n\n# Initialize network\nmodel = CNN(3,10,4,[11,9,7,5,3],64,True,0.1,2,'LeakyRelu').to(device)\n\n# Loss and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer=optim.Adam(model.parameters(),lr=learning_rate,weight_decay=0.0001)\n\n# Train Network\nfor epoch in range(epochs):\n    # Set the model to training mode\n    model.train()\n\n    for batch_idx, (data, targets) in enumerate(train_loader):\n        # Get data to cuda if possible\n        data = data.to(device=device)\n        targets = targets.to(device=device)\n        \n        optimizer.zero_grad()\n        # forward\n        scores = model(data)\n        loss = criterion(scores, targets)\n\n        # backward\n        \n        loss.backward()\n\n        # gradient descent or adam step\n        optimizer.step()\n        \n    # Set the model to evaluation mode\n    model.eval()\n\n    # Track the total loss and number of correct predictions\n    val_loss = 0\n    num_correct = 0\n    num_samples = 0\n\n    # Evaluate the model on the validation set\n    with torch.no_grad():\n        for data, targets in val_loader:\n            data = data.to(device=device)\n            targets = targets.to(device=device)\n\n            scores = model(data)\n            val_loss += criterion(scores, targets).item()\n\n            _, predictions = scores.max(1)\n            num_correct += (predictions == targets).sum()\n            num_samples += predictions.size(0)\n\n    # Calculate the average validation loss and accuracy\n    val_loss /= len(val_loader)\n    val_acc = float(num_correct) / num_samples\n\n    # Print the epoch number, loss, and accuracy\n    print('Epoch [{}/{}], Train Loss: {:.4f}, Val Loss: {:.4f}, Val Acc: {:.2f}%'\n          .format(epoch+1, epochs, loss.item(), val_loss, val_acc*100))\n\n# Check accuracy on training & test to see how good our model\n","metadata":{"execution":{"iopub.status.busy":"2023-04-07T09:37:27.711994Z","iopub.execute_input":"2023-04-07T09:37:27.713037Z","iopub.status.idle":"2023-04-07T09:41:11.669606Z","shell.execute_reply.started":"2023-04-07T09:37:27.712988Z","shell.execute_reply":"2023-04-07T09:41:11.667998Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"7999\n2000\n['.DS_Store', 'Amphibia', 'Animalia', 'Arachnida', 'Aves', 'Fungi', 'Insecta', 'Mammalia', 'Mollusca', 'Plantae', 'Reptilia']\nFeature Batch Shape: torch.Size([128, 3, 300, 300])\nLabel Batch Shape: torch.Size([128])\nok pool5\nr 300\nr 147\nr 71\nr 34\nr 17\nok flatten\n9\nEpoch [1/10], Train Loss: 2.1579, Val Loss: 2.1032, Val Acc: 25.00%\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_22/1827923373.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0;31m# Get data to cuda if possible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m             \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0mPIL\u001b[0m \u001b[0mImage\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRescaled\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \"\"\"\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mantialias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation, max_size, antialias)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Anti-alias option is always applied for PIL Image input. Argument antialias is ignored.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0mpil_interpolation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_modes_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF_pil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpil_interpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mF_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mantialias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mantialias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torchvision/transforms/functional_pil.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Got inappropriate size arg: {size}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   2190\u001b[0m                 )\n\u001b[1;32m   2191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2192\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2194\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"from signal import signal,SIGPIPE, SIG_DFL\nsignal(SIGPIPE,SIG_DFL)\n!pip install wandb -qU\nimport wandb\n!wandb login da816d14625ef44d200ee4acaa517646962e6f9a","metadata":{"execution":{"iopub.status.busy":"2023-04-07T10:25:05.890141Z","iopub.execute_input":"2023-04-07T10:25:05.891327Z","iopub.status.idle":"2023-04-07T10:25:18.579076Z","shell.execute_reply.started":"2023-04-07T10:25:05.891276Z","shell.execute_reply":"2023-04-07T10:25:18.577732Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"}]},{"cell_type":"code","source":"\nsweep_config = {\n    \"name\" : \"CS6910_Assignment_2_Q2\",\n    \"method\" : \"bayes\",\n    'metric': {\n        'name': 'val_acc',\n        'goal': 'maximize'\n    },\n    \"parameters\" : {\n        \"epochs\" : {\n            \"values\" : [10,15,20]\n        },\n        \"batch_size\": {\n            \"values\": [32, 64, 128]\n        },\n        'learning_rate':{\n            \"values\": [0.001,0.0001,0.0003,0.0005]\n        },\n        \"dropout\": {\n            \"values\": [0,0.2,0.3]\n        },\n        \"batch_norm\": {\n              \"values\": [True,False]\n        },\n        \"data_aug\": {\n              \"values\": [True,False]\n        },\n        'kernel_sizes':{\n            'values': [[3,3,3,3,3],[5,5,5,5,5],[7,5,5,3,3], [11,9,7,5,3]]\n        },\n        'filter_multiplier': {\n            'values': [1, 2, 0.5]\n        },\n        'num_filters': {\n            'values': [4,8,16]\n        },\n        \"fc_neurons\": {\n              \"values\": [32, 64, 128]\n          }        \n    }\n}\n\ndef calculate_accuracy(model, test_loader):\n    model.eval()\n    total = 0\n    correct = 0\n    with torch.no_grad():\n        for images, labels in test_loader:\n            images = images.to(device)\n            labels = labels.to(device)\n\n            outputs = model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    return 100 * correct / total\n\ndef train():\n    config_default={\n      'epochs':15,\n      'batch_size':32,\n      'learning_rate':0.001,\n      'dropout':0.3,\n      'batch_norm':True,\n      'data_aug':True,\n      'kernel_sizes':[5,5,5,5,5],\n      'filter_multiplier': 2,\n      'num_filters': 16,\n      \"fc_neurons\": 64\n  }\n    wandb.init(config=config_default)\n    c= wandb.config\n    name = \"nfliter_\"+str(c.num_filters)\n    wandb.init(name=name)\n\n    # Retrieve the hyperparameters from the config\n    lr = c.learning_rate\n    bs = c.batch_size\n    epochs = c.epochs\n    dp = c.dropout\n    bn = c.batch_norm\n    da=c.data_aug\n    ks=c.kernel_sizes\n    fm=c.filter_multiplier\n    nf=c.num_filters\n    fc=c.fc_neurons\n\n\n    # Load the dataset\n    train_loader,val_loader,test_loader,classes=load_data(bs,da)\n    \n    print(\"data loaded ====================================================\")\n\n    # Initialize network\n    model = CNN(3,10,nf,ks,fc,bn,dp,fm,'LeakyRelu').to(device)\n    print(\"model ini==============================================================\")\n    # Loss and optimizer\n    # Loss and optimizer\n    criterion = nn.CrossEntropyLoss()\n    optimizer=optim.Adam(model.parameters(),lr=lr,weight_decay=0.0001)\n\n    # Train Network\n    for epoch in range(epochs):\n        # Set the model to training mode\n        model.train()\n\n        for batch_idx, (data, targets) in enumerate(train_loader):\n            # Get data to cuda if possible\n            data = data.to(device)\n            targets = targets.to(device)\n\n            optimizer.zero_grad()\n            # forward\n            scores = model(data)\n            loss = criterion(scores, targets)\n\n            # backward\n\n            loss.backward()\n\n            # gradient descent or adam step\n            optimizer.step()          \n        # Calculate the test accuracy\n        train_acc = calculate_accuracy(model, train_loader)\n        val_acc = calculate_accuracy(model, val_loader)\n        test_acc = calculate_accuracy(model, test_loader)\n\n        # Log the metrics to WandB\n        wandb.log({'epoch': epoch+1, 'loss': loss.item(), 'test_acc': test_acc,'train_acc': train_acc,'val_acc': val_acc})\n\n\n    # Save the best model\n    wandb.save('model.pt')\n    return\n","metadata":{"execution":{"iopub.status.busy":"2023-04-07T10:32:36.479033Z","iopub.execute_input":"2023-04-07T10:32:36.479934Z","iopub.status.idle":"2023-04-07T10:32:36.511958Z","shell.execute_reply.started":"2023-04-07T10:32:36.479873Z","shell.execute_reply":"2023-04-07T10:32:36.510891Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"\n# Initialize the WandB sweep\nsweep_id = wandb.sweep(sweep_config, project='CS6910_Assignment_2_Q2')\nwandb.agent(sweep_id, function=train,count=5)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-07T10:32:38.936346Z","iopub.execute_input":"2023-04-07T10:32:38.937076Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Create sweep with ID: pcyv8fru\nSweep URL: https://wandb.ai/cs22s015/CS6910_Assignment_2_Q2/sweeps/pcyv8fru\n","output_type":"stream"},{"name":"stderr","text":"wandb: Waiting for W&B process to finish... (success).\nwandb: 🚀 View run effortless-sweep-4 at: https://wandb.ai/cs22s015/CS6910_Assignment_2_Q2/runs/7863emce\nwandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\nwandb: Find logs at: ./wandb/run-20230407_103201-7863emce/logs\n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: wsw03q65 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_norm: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_aug: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 20\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfc_neurons: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_multiplier: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_sizes: [5, 5, 5, 5, 5]\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: 16\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.14.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20230407_103245-wsw03q65</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs22s015/CS6910_Assignment_2_Q2/runs/wsw03q65' target=\"_blank\">volcanic-sweep-1</a></strong> to <a href='https://wandb.ai/cs22s015/CS6910_Assignment_2_Q2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs22s015/CS6910_Assignment_2_Q2/sweeps/pcyv8fru' target=\"_blank\">https://wandb.ai/cs22s015/CS6910_Assignment_2_Q2/sweeps/pcyv8fru</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs22s015/CS6910_Assignment_2_Q2' target=\"_blank\">https://wandb.ai/cs22s015/CS6910_Assignment_2_Q2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs22s015/CS6910_Assignment_2_Q2/sweeps/pcyv8fru' target=\"_blank\">https://wandb.ai/cs22s015/CS6910_Assignment_2_Q2/sweeps/pcyv8fru</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs22s015/CS6910_Assignment_2_Q2/runs/wsw03q65' target=\"_blank\">https://wandb.ai/cs22s015/CS6910_Assignment_2_Q2/runs/wsw03q65</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Finishing last run (ID:wsw03q65) before initializing another..."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">volcanic-sweep-1</strong> at: <a href='https://wandb.ai/cs22s015/CS6910_Assignment_2_Q2/runs/wsw03q65' target=\"_blank\">https://wandb.ai/cs22s015/CS6910_Assignment_2_Q2/runs/wsw03q65</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20230407_103245-wsw03q65/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Successfully finished last run (ID:wsw03q65). Initializing new run:<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.14.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20230407_103315-wsw03q65</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs22s015/CS6910_Assignment_2_Q2/runs/wsw03q65' target=\"_blank\">nfliter_16</a></strong> to <a href='https://wandb.ai/cs22s015/CS6910_Assignment_2_Q2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs22s015/CS6910_Assignment_2_Q2/sweeps/pcyv8fru' target=\"_blank\">https://wandb.ai/cs22s015/CS6910_Assignment_2_Q2/sweeps/pcyv8fru</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs22s015/CS6910_Assignment_2_Q2' target=\"_blank\">https://wandb.ai/cs22s015/CS6910_Assignment_2_Q2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs22s015/CS6910_Assignment_2_Q2/sweeps/pcyv8fru' target=\"_blank\">https://wandb.ai/cs22s015/CS6910_Assignment_2_Q2/sweeps/pcyv8fru</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs22s015/CS6910_Assignment_2_Q2/runs/wsw03q65' target=\"_blank\">https://wandb.ai/cs22s015/CS6910_Assignment_2_Q2/runs/wsw03q65</a>"},"metadata":{}},{"name":"stdout","text":"7999\n2000\ndata loaded ====================================================\nok pool5\nr 300\nr 150\nr 75\nr 37\nr 18\nok flatten\n9\nmodel ini==============================================================\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}